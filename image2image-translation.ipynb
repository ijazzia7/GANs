{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1365054,"sourceType":"datasetVersion","datasetId":795438},{"sourceId":7130035,"sourceType":"datasetVersion","datasetId":4113584},{"sourceId":7130179,"sourceType":"datasetVersion","datasetId":4113672}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-05T14:56:54.292472Z","iopub.execute_input":"2023-12-05T14:56:54.293137Z","iopub.status.idle":"2023-12-05T14:56:55.162595Z","shell.execute_reply.started":"2023-12-05T14:56:54.293105Z","shell.execute_reply":"2023-12-05T14:56:55.161374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nfrom keras.layers import Input, Dense, BatchNormalization, Flatten, Concatenate, Reshape, Embedding, Multiply\nfrom keras.layers import Conv2D, Conv2DTranspose, LeakyReLU, Activation, multiply, Dropout\nfrom keras.initializers import RandomNormal\nfrom keras.optimizers import Adam\nfrom keras.models import Model, Sequential\nfrom keras.preprocessing.image import load_img\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:56:55.164656Z","iopub.execute_input":"2023-12-05T14:56:55.165155Z","iopub.status.idle":"2023-12-05T14:57:07.886848Z","shell.execute_reply.started":"2023-12-05T14:56:55.165116Z","shell.execute_reply":"2023-12-05T14:57:07.885810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef load_images(path):\n    source_imgs=[]\n    target_imgs=[]\n    \n    imgs=os.listdir(path)\n    for i in tqdm(range(len(imgs))):\n        arr=np.array(load_img(f'{path}/{imgs[i]}', target_size=(256,512)))\n        source_imgs.append(arr[:,:256,:])\n        target_imgs.append(arr[:,256:,:])\n        \n    return np.array(source_imgs), np.array(target_imgs)\n\ntrain_s, train_t=load_images('/kaggle/input/pix2pix-maps/train')\nval_s, val_t=load_images('/kaggle/input/pix2pix-maps/val')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:58:26.616059Z","iopub.execute_input":"2023-12-05T14:58:26.616717Z","iopub.status.idle":"2023-12-05T14:58:48.370884Z","shell.execute_reply.started":"2023-12-05T14:58:26.616682Z","shell.execute_reply":"2023-12-05T14:58:48.369992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(3):\n    plt.subplot(2,3,i+1)\n    plt.imshow(train_s[i])\n    \nfor i in range(3,6):\n    plt.subplot(2,3 ,i+1)\n    plt.imshow(train_t[i-3])\n    \nplt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:22:51.715918Z","iopub.execute_input":"2023-12-05T13:22:51.716294Z","iopub.status.idle":"2023-12-05T13:22:52.526129Z","shell.execute_reply.started":"2023-12-05T13:22:51.716255Z","shell.execute_reply":"2023-12-05T13:22:52.525202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The discriminator is a deep convolutional neural network that performs image classification. Specifically, conditional-image classification. It takes both the source image (e.g. satellite photo) and the target image (e.g. Google maps image) as input and predicts the likelihood of whether target image is real or a fake translation of the source image.","metadata":{}},{"cell_type":"code","source":"def build_discriminator(image_shape):\n    \n    init = RandomNormal(stddev=0.02, seed=90)\n    \n    inp_s=Input(shape=image_shape)\n    inp_t=Input(shape=image_shape)   \n    merged=Concatenate()([inp_s, inp_t])\n    \n    d=Conv2D(64, (4,4), strides=(2,2),  padding='same', kernel_initializer=init)(merged)\n    d=LeakyReLU(alpha=0.2)(d)\n    \n    d=Conv2D(128, (4,4), strides=(2,2),  padding='same', kernel_initializer=init)(d) \n    d=BatchNormalization()(d)\n    d=LeakyReLU(alpha=0.2)(d)\n    \n    d=Conv2D(256, (4,4), strides=(2,2),  padding='same', kernel_initializer=init)(d)  \n    d=BatchNormalization()(d)\n    d=LeakyReLU(alpha=0.2)(d)\n    \n    d=Conv2D(512, (4,4), strides=(2,2),  padding='same', kernel_initializer=init)(d)  \n    d=BatchNormalization()(d)\n    d=LeakyReLU(alpha=0.2)(d)\n    \n    d=Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)  \n    d=BatchNormalization()(d)\n    d=LeakyReLU(alpha=0.2)(d)\n    \n    d=Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out=Activation('sigmoid')(d)\n    \n    model=Model([inp_s, inp_t], patch_out)\n    \n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    \n    return model\n\nimage_shape=(256,256,3)\ndisc=build_discriminator(image_shape)\ndisc.summary()\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:22:52.528076Z","iopub.execute_input":"2023-12-05T13:22:52.528382Z","iopub.status.idle":"2023-12-05T13:22:57.074362Z","shell.execute_reply.started":"2023-12-05T13:22:52.528354Z","shell.execute_reply":"2023-12-05T13:22:57.073387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(disc.predict([np.expand_dims(train_s[0], axis=0), np.expand_dims(train_t[0], axis=0)])[0])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:22:57.075614Z","iopub.execute_input":"2023-12-05T13:22:57.075928Z","iopub.status.idle":"2023-12-05T13:22:57.080332Z","shell.execute_reply.started":"2023-12-05T13:22:57.075900Z","shell.execute_reply":"2023-12-05T13:22:57.079396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The generator is an encoder-decoder model using a U-Net architecture. The model takes a source image (e.g. satellite photo) and generates a target image (e.g. Google maps image). It does this by first downsampling or encoding the input image down to a bottleneck layer, then upsampling or decoding the bottleneck representation to the size of the output image. The U-Net architecture means that skip-connections are added between the encoding layers and the corresponding decoding layers, forming a U-shape.\n### The encoder and decoder of the generator are comprised of standardized blocks of convolutional, batch normalization, dropout, and activation layers. This standardization means that we can develop helper functions to create each block of layers and call it repeatedly to build-up the encoder and decoder parts of the model.\n\n### The define_generator() function below implements the U-Net encoder-decoder generator model. It uses the define_encoder_block() helper function to create blocks of layers for the encoder and the decoder_block() function to create blocks of layers for the decoder. The tanh activation function is used in the output layer, meaning that pixel values in the generated image will be in the range [-1,1].","metadata":{}},{"cell_type":"code","source":"def encoding_block(inp, filters, bat=True):\n    init = RandomNormal(stddev=0.02)\n    d=Conv2D(filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(inp)\n    if bat:\n        d=BatchNormalization()(d,training=True)\n    d=LeakyReLU(alpha=0.2)(d)\n    return d\n\ndef decoding_block(inp, skip_in,filters, dropout=True):\n    init = RandomNormal(stddev=0.02)\n    u=Conv2DTranspose(filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(inp)\n    u=BatchNormalization()(u, training=True)\n    if dropout:\n        u=Dropout(0.5)(u)\n    u=Concatenate()([u, skip_in])\n    u=Activation('relu')(u)\n    return u\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:36.516173Z","iopub.execute_input":"2023-12-05T05:44:36.516479Z","iopub.status.idle":"2023-12-05T05:44:36.525272Z","shell.execute_reply.started":"2023-12-05T05:44:36.516454Z","shell.execute_reply":"2023-12-05T05:44:36.524110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_generator(image_shape):\n    init = RandomNormal(stddev=0.02)\n    inp_s=Input(shape=(256,256,3))\n    \n    d1=encoding_block(inp_s, 64, bat=False)\n    d2=encoding_block(d1, 128)\n    d3=encoding_block(d2, 256)\n    d4=encoding_block(d3, 512)\n    d5=encoding_block(d4, 512)\n    d6=encoding_block(d5, 512)\n    d7=encoding_block(d6, 512)\n    \n    bottleneck = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    bottleneck = Activation('relu')(bottleneck)\n    \n    u1 = decoding_block(bottleneck, d7, 512)\n    u2 = decoding_block(u1, d6, 512)\n    u3 = decoding_block(u2, d5, 512)\n    u4 = decoding_block(u3, d4, 512, dropout=False)\n    u5 = decoding_block(u4, d3, 256, dropout=False)\n    u6 = decoding_block(u5, d2, 128, dropout=False)\n    u7 = decoding_block(u6, d1, 64, dropout=False)\n\n    last = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(u7)\n    out_image = Activation('tanh')(last)\n    # define model\n    model = Model(inp_s, out_image)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:36.526595Z","iopub.execute_input":"2023-12-05T05:44:36.526917Z","iopub.status.idle":"2023-12-05T05:44:36.539988Z","shell.execute_reply.started":"2023-12-05T05:44:36.526891Z","shell.execute_reply":"2023-12-05T05:44:36.539022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_shape=(256,256,3)\ngen=build_generator(image_shape)\ngen.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:36.541209Z","iopub.execute_input":"2023-12-05T05:44:36.541501Z","iopub.status.idle":"2023-12-05T05:44:37.165334Z","shell.execute_reply.started":"2023-12-05T05:44:36.541475Z","shell.execute_reply":"2023-12-05T05:44:37.164370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_gan(g_model, d_model, image_shape):\n    \n    for layer in d_model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = False\n            \n    in_src = Input(shape=image_shape)\n    gen_out = g_model(in_src)\n    dis_out = d_model([in_src, gen_out])\n    \n    model = Model(in_src, [dis_out, gen_out])\n    \n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:37.168208Z","iopub.execute_input":"2023-12-05T05:44:37.168529Z","iopub.status.idle":"2023-12-05T05:44:37.175501Z","shell.execute_reply.started":"2023-12-05T05:44:37.168502Z","shell.execute_reply":"2023-12-05T05:44:37.174593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_gan(gen, disc, (256,256,3)).summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:37.176617Z","iopub.execute_input":"2023-12-05T05:44:37.176877Z","iopub.status.idle":"2023-12-05T05:44:37.527406Z","shell.execute_reply.started":"2023-12-05T05:44:37.176854Z","shell.execute_reply":"2023-12-05T05:44:37.526261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_real_samples(train_s, train_t):\n    train_s=(train_s-127.5)/127.5\n    train_t=(train_t-127.5)/127.5\n    \n    return [train_s, train_t]","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:57:07.888583Z","iopub.execute_input":"2023-12-05T14:57:07.889127Z","iopub.status.idle":"2023-12-05T14:57:07.893809Z","shell.execute_reply.started":"2023-12-05T14:57:07.889099Z","shell.execute_reply":"2023-12-05T14:57:07.892762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(dataset, n_samples, patch_shape):\n    train_s, train_t = dataset\n    ix = np.random.randint(0, train_s.shape[0], n_samples)\n    x1, x2 = train_s[ix], train_t[ix]\n    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n    \n    return [x1, x2], y","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:57:07.895124Z","iopub.execute_input":"2023-12-05T14:57:07.895500Z","iopub.status.idle":"2023-12-05T14:57:07.920636Z","shell.execute_reply.started":"2023-12-05T14:57:07.895464Z","shell.execute_reply":"2023-12-05T14:57:07.919833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(generator, samples, patch_shape):\n    fake = generator.predict(samples, verbose=0)\n    y = np.zeros((len(fake), patch_shape, patch_shape, 1))\n    return fake, y","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:57:07.922373Z","iopub.execute_input":"2023-12-05T14:57:07.922684Z","iopub.status.idle":"2023-12-05T14:57:07.934687Z","shell.execute_reply.started":"2023-12-05T14:57:07.922653Z","shell.execute_reply":"2023-12-05T14:57:07.933803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def summarize_performance(step, g_model, dataset, n_samples=3):\n    # select a sample of input images\n    [X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n    # generate a batch of fake samples\n    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n    # scale all pixels from [-1,1] to [0,1]\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    # plot real source images\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + i)\n        plt.axis('off')\n        plt.imshow(X_realA[i])\n    # plot generated target image\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples + i)\n        plt.axis('off')\n        plt.imshow(X_fakeB[i])\n    # plot real target image\n    for i in range(n_samples):\n        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n        plt.axis('off')\n        plt.imshow(X_realB[i])\n    # save plot to file\n    filename1 = 'plot_%06d.png' % (step+1)\n    plt.savefig(filename1)\n    plt.close()\n    # save the generator model\n    filename2 = 'model_%06d.keras' % (step+1)\n    g_model.save(filename2)\n    print('>Saved: %s and %s' % (filename1, filename2))","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:37.559009Z","iopub.execute_input":"2023-12-05T05:44:37.559414Z","iopub.status.idle":"2023-12-05T05:44:37.572879Z","shell.execute_reply.started":"2023-12-05T05:44:37.559372Z","shell.execute_reply":"2023-12-05T05:44:37.571117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n\n    n_patch = d_model.output_shape[1]\n\n    trainA, trainB = dataset\n\n    bat_per_epo = int(len(trainA) / n_batch)\n\n    n_steps = bat_per_epo * n_epochs\n\n    for i in tqdm(range(n_steps)):\n        \n        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n\n        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n\n        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n\n        #print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n\n        if (i+1) % (bat_per_epo * 10) == 0:\n            summarize_performance(i, g_model, dataset)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:44:37.574161Z","iopub.execute_input":"2023-12-05T05:44:37.574590Z","iopub.status.idle":"2023-12-05T05:44:37.584533Z","shell.execute_reply.started":"2023-12-05T05:44:37.574513Z","shell.execute_reply":"2023-12-05T05:44:37.583623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = load_real_samples(train_s, train_t)\nprint('Loaded', dataset[0].shape, dataset[1].shape)\n\nimage_shape = dataset[0].shape[1:]\n\nd_model = build_discriminator(image_shape)\ng_model = build_generator(image_shape)\n\ngan_model = build_gan(g_model, d_model, image_shape)\n\ntrain(d_model, g_model, gan_model, dataset, n_epochs=200)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T05:45:04.869270Z","iopub.execute_input":"2023-12-05T05:45:04.869689Z","iopub.status.idle":"2023-12-05T05:49:01.884840Z","shell.execute_reply.started":"2023-12-05T05:45:04.869657Z","shell.execute_reply":"2023-12-05T05:49:01.883813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator=keras.models.load_model('/kaggle/input/modell/model_054800.keras')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:57:14.085635Z","iopub.execute_input":"2023-12-05T14:57:14.086412Z","iopub.status.idle":"2023-12-05T14:57:46.037843Z","shell.execute_reply.started":"2023-12-05T14:57:14.086375Z","shell.execute_reply":"2023-12-05T14:57:46.036793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_s","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:58:21.192426Z","iopub.execute_input":"2023-12-05T14:58:21.192869Z","iopub.status.idle":"2023-12-05T14:58:21.230192Z","shell.execute_reply.started":"2023-12-05T14:58:21.192830Z","shell.execute_reply":"2023-12-05T14:58:21.229009Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_s, train_t = load_real_samples(train_s, train_t)\nval_s, val_t = load_real_samples(val_s, val_t)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:59:40.097817Z","iopub.execute_input":"2023-12-05T14:59:40.098158Z","iopub.status.idle":"2023-12-05T14:59:42.981308Z","shell.execute_reply.started":"2023-12-05T14:59:40.098131Z","shell.execute_reply":"2023-12-05T14:59:42.980259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:02:57.616715Z","iopub.execute_input":"2023-12-05T14:02:57.617367Z","iopub.status.idle":"2023-12-05T14:02:57.730722Z","shell.execute_reply.started":"2023-12-05T14:02:57.617335Z","shell.execute_reply":"2023-12-05T14:02:57.729682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ix=np.random.randint(0,1096-3,1)[0]\nimgs,_ = generate_fake_samples(generator, val_s[ix:ix+3], 16)\n\nfor i in range(3):\n    plt.subplot(3,3,i+1)\n    plt.imshow(val_s[ix:ix+3][i])\n    \nfor i in range(3,6):\n    plt.subplot(3,3 ,i+1)\n    plt.imshow(val_t[ix:ix+3][i-3])\n    \nfor i in range(6,9):\n    plt.subplot(3,3 ,i+1)\n    plt.imshow(imgs[i-6])\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T14:59:50.540431Z","iopub.execute_input":"2023-12-05T14:59:50.540788Z","iopub.status.idle":"2023-12-05T15:00:01.273286Z","shell.execute_reply.started":"2023-12-05T14:59:50.540761Z","shell.execute_reply":"2023-12-05T15:00:01.272307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ni=plt.imread('/kaggle/input/images/Screenshot 2023-12-05 at 6.38.18 PM.png')\ni=i[:,:,:3]\n\noriginal_image = Image.open(\"/kaggle/input/images/Screenshot 2023-12-05 at 6.38.18 PM.png\")\n\n# Define the new size (width, height)\nnew_size = (256, 256)\n\n# Resize the image\nresized_image = original_image.resize(new_size)\nimg=np.array(resized_image)[:,:,:3]\nimg=(img-127.5)/127.5\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:06:38.809098Z","iopub.execute_input":"2023-12-05T15:06:38.809526Z","iopub.status.idle":"2023-12-05T15:06:38.853392Z","shell.execute_reply.started":"2023-12-05T15:06:38.809493Z","shell.execute_reply":"2023-12-05T15:06:38.852624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:06:46.571394Z","iopub.execute_input":"2023-12-05T15:06:46.572292Z","iopub.status.idle":"2023-12-05T15:06:46.896289Z","shell.execute_reply.started":"2023-12-05T15:06:46.572257Z","shell.execute_reply":"2023-12-05T15:06:46.895394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img,_=generate_fake_samples(generator, np.expand_dims(img, axis=0), 16)\nplt.imshow(img[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T15:07:06.645108Z","iopub.execute_input":"2023-12-05T15:07:06.645840Z","iopub.status.idle":"2023-12-05T15:07:07.788845Z","shell.execute_reply.started":"2023-12-05T15:07:06.645807Z","shell.execute_reply":"2023-12-05T15:07:07.787803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_s[52])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T13:59:58.895992Z","iopub.execute_input":"2023-12-05T13:59:58.896384Z","iopub.status.idle":"2023-12-05T13:59:59.174979Z","shell.execute_reply.started":"2023-12-05T13:59:58.896349Z","shell.execute_reply":"2023-12-05T13:59:59.173931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}